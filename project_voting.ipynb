{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #3\n",
    "## Predicting Voting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import mapclassify\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('./va_admin_bndry/VirginiaCounty_ClippedToShoreline.shx')\n",
    "vdf = pd.read_csv('./data/voting_VA.csv')\n",
    "cdf = pd.read_csv('./data/county_adjacencies.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['FIPS_left'] = pd.to_numeric(gdf['STCOFIPS']) \n",
    "df = gdf.merge(cdf,left_on='FIPS_left',right_on='FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in vdf['year'].unique():\n",
    "    df20 = vdf.loc[ vdf['year']==y,:]\n",
    "\n",
    "    Dvotes = df20.loc[(df20['party']=='DEMOCRAT'),:].groupby('county_fips')['candidatevotes'].sum()\n",
    "    Dvotes = Dvotes.rename('dem_votes_' + str(y))\n",
    "    df = df.merge(Dvotes,left_on='FIPS_left',right_on='county_fips')\n",
    "\n",
    "    Rvotes = df20.loc[(df20['party']=='REPUBLICAN'),:].groupby('county_fips')['candidatevotes'].sum()\n",
    "    Rvotes = Rvotes.rename('rep_votes_' + str(y))\n",
    "    df = df.merge(Rvotes,left_on='FIPS_left',right_on='county_fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleans data by extracting votes by year for each county\n",
    "def extract_df(index):\n",
    "    row = df.iloc[index]\n",
    "    years = []\n",
    "    dem_votes = []\n",
    "    rep_votes = []\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column.startswith('dem_votes'):\n",
    "            year = column.split('_')[-1]\n",
    "            years.append(year)\n",
    "            dem_votes.append(row[column])\n",
    "            rep_votes.append(row['rep_votes_' + year])\n",
    "\n",
    "    result_df = pd.DataFrame({'dem_votes': dem_votes, 'rep_votes': rep_votes})\n",
    "    result_df['vote_diff'] = result_df['rep_votes']-result_df['dem_votes']\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensemble(df):\n",
    "    # Split data into training rows and testing rows:\n",
    "    N = df.shape[0]\n",
    "    df = df.sample(frac=1, random_state=100) # randomize the order in which data appears\n",
    "    train_size = int(.8*N)\n",
    "    df_train = df[0:train_size]\n",
    "    N_train = df_train.shape[0]\n",
    "    df_test = df[train_size:]\n",
    "    N_test = df_test.shape[0]\n",
    "\n",
    "    # Bootstrap:\n",
    "    T = 1000\n",
    "    m_depth = 5\n",
    "    Rsq = np.zeros(T) # preallocate the rsq measure\n",
    "    y_test_hat = np.zeros([T,N_test]) # preallocate predictions on test set\n",
    "    df_train.head()\n",
    "\n",
    "    # Split data into train/test:\n",
    "    X_train = df_train.drop(['vote_diff'],axis=1)\n",
    "    y_train = df_train['vote_diff']\n",
    "    X_test = df_test.drop(['vote_diff'],axis=1)\n",
    "    y_test = df_test['vote_diff']\n",
    "    \n",
    "    for s in range(T):\n",
    "        # Generate a bootstrap sample:\n",
    "        df_s = df_train.sample(frac=1, replace=True)\n",
    "        X_s = df_s.drop('vote_diff',axis=1)\n",
    "        y_s = df_s['vote_diff']\n",
    "        # Fit decision tree:\n",
    "        cart = tree.DecisionTreeRegressor(max_depth=m_depth) # Create a classifier object\n",
    "        cart = cart.fit(X_s, y_s) # Fit the classifier\n",
    "        # Compute Rsq:\n",
    "        y_hat = cart.predict(X_test)\n",
    "        SSE = np.sum( (y_test-y_hat)**2 )\n",
    "        TSS = np.sum( (y_test-y_s.mean())**2 )\n",
    "        Rsq[s] = 1 - SSE/TSS\n",
    "        # Make and Save Predictions:\n",
    "        y_test_hat[s,:] = y_hat\n",
    "    \n",
    "    # Ensemble predictor:\n",
    "    y_hat_ensemble = y_test_hat.mean(axis=0) # Average the columns to get the ensemble prediction\n",
    "    SSE = np.sum( (y_test-y_hat_ensemble)**2 )\n",
    "    TSS = np.sum( (y_test-y_train.mean())**2 )\n",
    "    Rsq_ensemble = 1 - SSE/TSS\n",
    "\n",
    "    return Rsq_ensemble\n",
    "    # print(Rsq_ensemble)\n",
    "\n",
    "    # print(y_hat_ensemble.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.428732899137919\n",
      "1221.7515\n",
      "0.25696501517213255\n",
      "-8229.983\n",
      "0.6023659080974642\n",
      "1628.1399999999999\n"
     ]
    }
   ],
   "source": [
    "ensemble(extract_df(0))\n",
    "ensemble(extract_df(1))\n",
    "ensemble(extract_df(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    ensemble(extract_df(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
