{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #3\n",
    "## Predicting Voting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import mapclassify\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('./va_admin_bndry/VirginiaCounty_ClippedToShoreline.shx')\n",
    "vdf = pd.read_csv('./data/voting_VA.csv')\n",
    "cdf = pd.read_csv('./data/county_adjacencies.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['FIPS_left'] = pd.to_numeric(gdf['STCOFIPS']) \n",
    "df = gdf.merge(cdf,left_on='FIPS_left',right_on='FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in vdf['year'].unique():\n",
    "    df20 = vdf.loc[ vdf['year']==y,:]\n",
    "\n",
    "    Dvotes = df20.loc[(df20['party']=='DEMOCRAT'),:].groupby('county_fips')['candidatevotes'].sum()\n",
    "    Dvotes = Dvotes.rename('dem_votes_' + str(y))\n",
    "    df = df.merge(Dvotes,left_on='FIPS_left',right_on='county_fips')\n",
    "\n",
    "    Rvotes = df20.loc[(df20['party']=='REPUBLICAN'),:].groupby('county_fips')['candidatevotes'].sum()\n",
    "    Rvotes = Rvotes.rename('rep_votes_' + str(y))\n",
    "    df = df.merge(Rvotes,left_on='FIPS_left',right_on='county_fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleans data by extracting votes by year for each county\n",
    "def extract_df(index):\n",
    "    row = df.iloc[index]\n",
    "    years = []\n",
    "    dem_votes = []\n",
    "    rep_votes = []\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column.startswith('dem_votes'):\n",
    "            year = column.split('_')[-1]\n",
    "            years.append(year)\n",
    "            dem_votes.append(row[column])\n",
    "            rep_votes.append(row['rep_votes_' + year])\n",
    "\n",
    "    result_df = pd.DataFrame({'dem_votes': dem_votes, 'rep_votes': rep_votes})\n",
    "    result_df['vote_diff'] = result_df['rep_votes']-result_df['dem_votes']\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensemble(df):\n",
    "    # Split data into training rows and testing rows:\n",
    "    N = df.shape[0]\n",
    "    df = df.sample(frac=1, random_state=100) # randomize the order in which data appears\n",
    "    train_size = int(.8*N)\n",
    "    df_train = df[0:train_size]\n",
    "    N_train = df_train.shape[0]\n",
    "    df_test = df[train_size:]\n",
    "    N_test = df_test.shape[0]\n",
    "\n",
    "    # Bootstrap:\n",
    "    T = 300\n",
    "    m_depth = 4\n",
    "    Rsq = np.zeros(T) # preallocate the rsq measure\n",
    "    y_test_hat = np.zeros([T,N_test]) # preallocate predictions on test set\n",
    "    df_train.head()\n",
    "\n",
    "    # Split data into train/test:\n",
    "    X_train = df_train.drop(['vote_diff'],axis=1)\n",
    "    y_train = df_train['vote_diff']\n",
    "    X_test = df_test.drop(['vote_diff'],axis=1)\n",
    "    y_test = df_test['vote_diff']\n",
    "    \n",
    "    for s in range(T):\n",
    "        # Generate a bootstrap sample:\n",
    "        df_s = df_train.sample(frac=1, replace=True)\n",
    "        X_s = df_s.drop('vote_diff',axis=1)\n",
    "        y_s = df_s['vote_diff']\n",
    "        # Fit decision tree:\n",
    "        cart = tree.DecisionTreeRegressor(max_depth=m_depth) # Create a classifier object\n",
    "        cart = cart.fit(X_s, y_s) # Fit the classifier\n",
    "        # Compute Rsq:\n",
    "        y_hat = cart.predict(X_test)\n",
    "        SSE = np.sum( (y_test-y_hat)**2 )\n",
    "        TSS = np.sum( (y_test-y_s.mean())**2 )\n",
    "        Rsq[s] = 1 - SSE/TSS\n",
    "        # Make and Save Predictions:\n",
    "        y_test_hat[s,:] = y_hat\n",
    "    \n",
    "    # Ensemble predictor:\n",
    "    y_hat_ensemble = y_test_hat.mean(axis=0) # Average the columns to get the ensemble prediction\n",
    "    SSE = np.sum( (y_test-y_hat_ensemble)**2 )\n",
    "    TSS = np.sum( (y_test-y_train.mean())**2 )\n",
    "    Rsq_ensemble = 1 - SSE/TSS\n",
    "\n",
    "    return Rsq_ensemble\n",
    "    # print(Rsq_ensemble)\n",
    "\n",
    "    # print(y_hat_ensemble.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19970320872586966\n"
     ]
    }
   ],
   "source": [
    "r_avg = 0\n",
    "total = 0\n",
    "for i in range(len(df)):\n",
    "    r_avg += ensemble(extract_df(i))\n",
    "    total += 1\n",
    "\n",
    "r_avg /= total\n",
    "print(r_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
